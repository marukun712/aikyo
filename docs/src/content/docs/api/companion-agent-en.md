---
title: Companion Agent
description: API reference for the CompanionAgent class
---
The `CompanionAgent` class manages the core logic for an AI companion. It integrates the agent, memory, workflow, and duplicate detection to handle message processing and state generation.

## Import Statement

```typescript
import { CompanionAgent } from "@aikyo/server";
```

## Constructor

```typescript
constructor(
  companion: CompanionCard,
  model: LanguageModel,
  history: Message[],
  config?: { maxTurn: number | null; enableRepetitionJudge: boolean }
)
```

### Parameters

| Parameter       | Type                   | Description                                                           | Default Value    |
|-----------------|------------------------|-----------------------------------------------------------------------|------------------|
| `companion`     | `CompanionCard`        | Companion configuration including metadata, tools, and events.       | -               |
| `model`         | `LanguageModel`        | The LLM model to be used (retrieved from `@ai-sdk/*`).                | -               |
| `history`       | `Message[]`            | Array of conversation history passed by reference.                    | -               |
| `config`        | `object`               | Optional configuration settings.                                     | `{ maxTurn: null, enableRepetitionJudge: true }` |
| `config.maxTurn` | `number \| null`       | Maximum number of turns before forced termination.                    | `null` (no limit) |
| `config.enableRepetitionJudge` | `boolean`              | Enable/disable duplicate detection functionality.                     | `true`           |

### Usage Example

```typescript
import { CompanionAgent } from "@aikyo/server";
import { anthropic } from "@ai-sdk/anthropic";
import type { Message } from "@aikyo/server";

const history: Message[] = [];

const companion = new CompanionAgent(
  companionCard,
  anthropic("claude-3-5-haiku-latest"),
  history,
  {
    maxTurn: 20,                    // Terminate after 20 turns
    enableRepetitionJudge: true     // Enable duplicate detection
  }
);
```

**Supported LLM Providers**

- **Anthropic**: `@ai-sdk/anthropic`
- **Google**: `@ai-sdk/google`

## Properties

### companion

```typescript
companion: CompanionCard
```

The configuration card for the companion.

### agent

```typescript
agent: Agent
```

An instance of the Mastra Agent that manages interactions with the LLM.

### repetitionJudge

```typescript
repetitionJudge: RepetitionJudge
```

A judge for detecting conversation duplicates. See [Duplicate Detection](../core/repetition) for details.

### stateJudge

```typescript
stateJudge: StateJudge
```

A judge that generates the companion's state (State) based on the conversation history. Used for turn-taking functionality.

### history

```typescript
history: Message[]
```

Array of conversation history passed by reference.

### memory

```typescript
memory: Memory
```

An instance of the `Memory` class managing long-term and working memory.

**Persistence:**

- Creates a LibSQL database at `db/<companion_id>.db`.
- Utilizes LibSQLStore for storage and LibSQLVector for vector store, enabling similarity searches via the vector store.

**Working Memory Schema:**

```typescript
export const MemorySchema = z.object({
  messages: z.array(
    z.object({
      from: z.string().describe("ID of the companion who sent the message"),
      content: z.string().describe("Summary of the message content"),
    }),
  ),
});
```

### runtimeContext

```typescript
runtimeContext: RuntimeContext
```

The runtime context referenced during tool execution, containing the following information:

| Key       | Type     | Description                          |
|-----------|----------|--------------------------------------|
| `id`      | `string` | Companion's ID                       |
| `libp2p`  | `Libp2p` | libp2p instance                      |
| `companions` | `Map<string, Metadata>` | List of connected companions         |
| `pendingQueries` | `Map` | Pending queries                     |
| `agent`   | `CompanionAgent`              | The agent itself                     |

### run

```typescript
run: Run
```

A Run instance of the workflow generated by `createToolInstructionWorkflow`.

### count

```typescript
count: number
```

Current turn count (used when `maxTurn` configuration is enabled).

### config

```typescript
config: { maxTurn: number | null; enableRepetitionJudge: boolean }
```

Configuration passed to the constructor.

## Methods

### generateToolInstruction()

Receives a message and generates tool execution instructions by evaluating a CEL expression.

```typescript
async generateToolInstruction(input: Message): Promise<string>
```

**Parameters:**

- `input`: The received message

**Returns:**

- `string`: Tool execution instruction (e.g., "Introduce yourself. Use the tool to respond.")
  or `"failed"` if event execution fails.

**Process Flow:**

1. In Workflow's `evaluateStep`, the LLM evaluates the `params` schema.
2. In `runStep`, the CEL expression is checked based on the condition.
3. Concatenates and returns the `instruction` for the matched condition.

### generateState()

Generates the companion's state (State) based on the entire conversation history.

```typescript
async generateState(): Promise<State>
```

**Parameters:**

None (internally references `this.history`)

**Returns:**

- `State`: State information including speak/listen, importance, selected, and closing status.

**Process Flow:**

1. Performs duplicate detection if `enableRepetitionJudge` is `true`.
2. Adds a closing instruction if the score > 0.7.
3. Generates the State using `StateJudge`.
4. Checks for `maxTurn` limit (if configured).

For more details, see [Turn-Taking](../core/turn-taking#state-state-generation).

### input()

Receives a message and executes the LLM based on the tool execution instructions.

```typescript
async input(message: Message): Promise<void>
```

**Parameters:**

- `message`: The received message

**Process Flow:**

1. Retrieves tool execution instructions using `generateToolInstruction`.
2. Executes the LLM with the instruction and the message.
3. The LLM automatically executes tools as needed.